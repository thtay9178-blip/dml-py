{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from dml-py.trainers import DMLTrainer\n",
    "from dml-py.models.cifar import resnet20, wrn_16_2\n",
    "from dml-py.analysis import LossLandscape, RobustnessAnalyzer\n",
    "from dml-py.analysis.visualization import plot_training_curves, plot_knowledge_flow\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bcd7c8",
   "metadata": {},
   "source": [
    "## 1. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c9e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Train DML\n",
    "models = [resnet20(10), wrn_16_2(10)]\n",
    "trainer = DMLTrainer(models, learning_rate=0.1, temperature=3)\n",
    "\n",
    "results = trainer.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=30,\n",
    "    save_checkpoints=True,\n",
    "    checkpoint_dir='checkpoints'\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec2383",
   "metadata": {},
   "source": [
    "## 2. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c30c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy curves\n",
    "plot_training_curves(\n",
    "    results,\n",
    "    metrics=['model_0_acc', 'model_1_acc', 'avg_acc'],\n",
    "    title='DML Training - Test Accuracy',\n",
    "    save_path='training_accuracy.png'\n",
    ")\n",
    "\n",
    "# Plot loss curves\n",
    "plot_training_curves(\n",
    "    results,\n",
    "    metrics=['train_loss', 'kl_loss'],\n",
    "    title='DML Training - Losses',\n",
    "    save_path='training_loss.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26610a19",
   "metadata": {},
   "source": [
    "## 3. Loss Landscape Visualization\n",
    "\n",
    "Visualize the loss surface around trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml-py.analysis import LossLandscape\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create loss landscape analyzer\n",
    "landscape = LossLandscape(\n",
    "    model=trainer.models[0],\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    dataloader=test_loader\n",
    ")\n",
    "\n",
    "# Plot 1D loss curve\n",
    "landscape.plot_1d(\n",
    "    'loss_landscape_1d.png',\n",
    "    alpha_min=-1.0,\n",
    "    alpha_max=1.0,\n",
    "    num_points=51\n",
    ")\n",
    "\n",
    "# Plot 2D loss surface\n",
    "landscape.plot_2d(\n",
    "    'loss_landscape_2d.png',\n",
    "    alpha_min=-0.5,\n",
    "    alpha_max=0.5,\n",
    "    beta_min=-0.5,\n",
    "    beta_max=0.5,\n",
    "    num_points=20\n",
    ")\n",
    "\n",
    "print(\"✓ Loss landscape plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de9dc42",
   "metadata": {},
   "source": [
    "## 4. Knowledge Flow Visualization\n",
    "\n",
    "See how models transfer knowledge to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot knowledge flow heatmap\n",
    "plot_knowledge_flow(\n",
    "    trainer,\n",
    "    test_loader,\n",
    "    save_path='knowledge_flow.png'\n",
    ")\n",
    "\n",
    "# This shows:\n",
    "# - Which models learn more from which peers\n",
    "# - KL divergence between model predictions\n",
    "# - Mutual information flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb985a",
   "metadata": {},
   "source": [
    "## 5. Model Agreement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_agreement(models, dataloader):\n",
    "    \"\"\"Compute how often models agree on predictions.\"\"\"\n",
    "    agreements = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.cuda() if torch.cuda.is_available() else inputs\n",
    "            \n",
    "            # Get predictions from all models\n",
    "            preds = [model(inputs).argmax(dim=1) for model in models]\n",
    "            \n",
    "            # Check if all models agree\n",
    "            for i in range(len(preds[0])):\n",
    "                all_same = all(p[i] == preds[0][i] for p in preds)\n",
    "                agreements.append(all_same)\n",
    "    \n",
    "    return np.mean(agreements) * 100\n",
    "\n",
    "agreement = compute_agreement(trainer.models, test_loader)\n",
    "print(f\"Model agreement: {agreement:.2f}%\")\n",
    "print(f\"Disagreement: {100-agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234ae80",
   "metadata": {},
   "source": [
    "## 6. Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec062c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml-py.analysis import RobustnessAnalyzer\n",
    "\n",
    "# Analyze robustness to noise\n",
    "analyzer = RobustnessAnalyzer(trainer.models[0])\n",
    "\n",
    "# Test with different noise levels\n",
    "noise_levels = [0.0, 0.05, 0.1, 0.15, 0.2]\n",
    "accuracies = []\n",
    "\n",
    "for noise in noise_levels:\n",
    "    acc = analyzer.evaluate_with_noise(test_loader, noise_std=noise)\n",
    "    accuracies.append(acc)\n",
    "    print(f\"Noise std={noise:.2f}: Accuracy={acc:.2f}%\")\n",
    "\n",
    "# Plot robustness curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(noise_levels, accuracies, 'b-o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Noise Standard Deviation', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Model Robustness to Input Noise', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('robustness_plot.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa168ce",
   "metadata": {},
   "source": [
    "## 7. Prediction Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dedd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def analyze_confidence(model, dataloader):\n",
    "    \"\"\"Analyze prediction confidence distribution.\"\"\"\n",
    "    confidences_correct = []\n",
    "    confidences_incorrect = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.cuda() if torch.cuda.is_available() else inputs\n",
    "            targets = targets.cuda() if torch.cuda.is_available() else targets\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            max_probs, preds = probs.max(dim=1)\n",
    "            \n",
    "            # Separate by correctness\n",
    "            correct_mask = preds == targets\n",
    "            confidences_correct.extend(max_probs[correct_mask].cpu().numpy())\n",
    "            confidences_incorrect.extend(max_probs[~correct_mask].cpu().numpy())\n",
    "    \n",
    "    return confidences_correct, confidences_incorrect\n",
    "\n",
    "# Analyze both models\n",
    "conf_correct_1, conf_incorrect_1 = analyze_confidence(trainer.models[0], test_loader)\n",
    "conf_correct_2, conf_incorrect_2 = analyze_confidence(trainer.models[1], test_loader)\n",
    "\n",
    "# Plot confidence distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Model 1\n",
    "axes[0].hist(conf_correct_1, bins=50, alpha=0.7, label='Correct', color='green')\n",
    "axes[0].hist(conf_incorrect_1, bins=50, alpha=0.7, label='Incorrect', color='red')\n",
    "axes[0].set_xlabel('Confidence', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Model 1 - Prediction Confidence', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Model 2\n",
    "axes[1].hist(conf_correct_2, bins=50, alpha=0.7, label='Correct', color='green')\n",
    "axes[1].hist(conf_incorrect_2, bins=50, alpha=0.7, label='Incorrect', color='red')\n",
    "axes[1].set_xlabel('Confidence', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Model 2 - Prediction Confidence', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confidence_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nModel 1 - Avg confidence (correct): {np.mean(conf_correct_1):.3f}\")\n",
    "print(f\"Model 1 - Avg confidence (incorrect): {np.mean(conf_incorrect_1):.3f}\")\n",
    "print(f\"\\nModel 2 - Avg confidence (correct): {np.mean(conf_correct_2):.3f}\")\n",
    "print(f\"Model 2 - Avg confidence (incorrect): {np.mean(conf_incorrect_2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b17a71",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "✅ Visualize training curves and metrics  \n",
    "✅ Plot loss landscapes  \n",
    "✅ Analyze knowledge flow between models  \n",
    "✅ Measure model agreement  \n",
    "✅ Test robustness to noise  \n",
    "✅ Analyze prediction confidence  \n",
    "\n",
    "These tools help you:\n",
    "- Understand what models are learning\n",
    "- Debug training issues\n",
    "- Compare different approaches\n",
    "- Ensure model quality\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Apply these analyses to your own models\n",
    "- Create custom visualization functions\n",
    "- Check out `05_deployment.ipynb` for production deployment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

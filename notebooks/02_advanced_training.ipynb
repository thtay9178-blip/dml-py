{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fe7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from dml-py.trainers import DMLTrainer\n",
    "from dml-py.models.cifar import resnet20, wrn_16_2, mobilenet_v2\n",
    "from dml-py.strategies import CurriculumLearning, PeerSelection, TemperatureScaling\n",
    "from dml-py.utils import AMPConfig, apply_amp_to_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21859e3b",
   "metadata": {},
   "source": [
    "## 1. Curriculum Learning\n",
    "\n",
    "Start with easy examples and gradually increase difficulty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03166f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Create curriculum learning strategy\n",
    "curriculum = CurriculumLearning(\n",
    "    num_stages=3,\n",
    "    difficulty_fn=lambda epoch: min(1.0, epoch / 30),  # Gradually increase difficulty\n",
    "    start_easy=True\n",
    ")\n",
    "\n",
    "# Train with curriculum\n",
    "models = [resnet20(10), wrn_16_2(10)]\n",
    "trainer = DMLTrainer(models)\n",
    "\n",
    "# Apply curriculum learning\n",
    "curriculum.apply(trainer)\n",
    "\n",
    "results = trainer.train(train_loader, test_loader, epochs=50)\n",
    "print(f\"Final accuracy with curriculum: {results['avg_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee048ff",
   "metadata": {},
   "source": [
    "## 2. Peer Selection\n",
    "\n",
    "Adaptively select which peers to learn from based on performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml-py.strategies import PeerSelection\n",
    "\n",
    "# Create 4 models of different sizes\n",
    "models = [\n",
    "    resnet20(10),\n",
    "    wrn_16_2(10),\n",
    "    mobilenet_v2(10),\n",
    "    resnet20(10)  # Another ResNet\n",
    "]\n",
    "\n",
    "# Initialize peer selection\n",
    "peer_selector = PeerSelection(\n",
    "    selection_strategy='performance',  # Choose best performing peers\n",
    "    top_k=2,  # Learn from top 2 peers only\n",
    "    update_frequency=5  # Update peer rankings every 5 epochs\n",
    ")\n",
    "\n",
    "trainer = DMLTrainer(models)\n",
    "peer_selector.apply(trainer)\n",
    "\n",
    "results = trainer.train(train_loader, test_loader, epochs=30)\n",
    "\n",
    "# Show which peers were selected\n",
    "print(\"\\nPeer selection history:\")\n",
    "for epoch, selected in peer_selector.selection_history.items():\n",
    "    print(f\"Epoch {epoch}: Selected peers {selected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a520ab",
   "metadata": {},
   "source": [
    "## 3. Temperature Scaling\n",
    "\n",
    "Dynamically adjust temperature during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml-py.strategies import TemperatureScaling\n",
    "\n",
    "# Create temperature scheduler\n",
    "temp_scheduler = TemperatureScaling(\n",
    "    initial_temperature=4.0,\n",
    "    final_temperature=2.0,\n",
    "    schedule='cosine',  # Cosine annealing\n",
    "    warmup_epochs=5\n",
    ")\n",
    "\n",
    "models = [resnet20(10), wrn_16_2(10)]\n",
    "trainer = DMLTrainer(models, temperature=4.0)\n",
    "\n",
    "# Apply temperature scaling\n",
    "temp_scheduler.apply(trainer)\n",
    "\n",
    "results = trainer.train(train_loader, test_loader, epochs=50)\n",
    "\n",
    "# Plot temperature schedule\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(temp_scheduler.temperature_history, linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Temperature Schedule')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7be64",
   "metadata": {},
   "source": [
    "## 4. Mixed Precision Training\n",
    "\n",
    "Train faster with automatic mixed precision (AMP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml-py.utils import AMPConfig, apply_amp_to_trainer\n",
    "import time\n",
    "\n",
    "models = [resnet20(10), wrn_16_2(10)]\n",
    "\n",
    "# Train WITHOUT AMP (baseline)\n",
    "trainer_fp32 = DMLTrainer(models)\n",
    "start = time.time()\n",
    "trainer_fp32.train(train_loader, test_loader, epochs=10)\n",
    "time_fp32 = time.time() - start\n",
    "\n",
    "# Train WITH AMP\n",
    "models = [resnet20(10), wrn_16_2(10)]  # Reset models\n",
    "trainer_amp = DMLTrainer(models)\n",
    "\n",
    "amp_config = AMPConfig(\n",
    "    enabled=True,\n",
    "    dtype=torch.float16\n",
    ")\n",
    "trainer_amp = apply_amp_to_trainer(trainer_amp, amp_config)\n",
    "\n",
    "start = time.time()\n",
    "trainer_amp.train(train_loader, test_loader, epochs=10)\n",
    "time_amp = time.time() - start\n",
    "\n",
    "# Compare\n",
    "speedup = time_fp32 / time_amp\n",
    "print(f\"\\nTraining Time:\")\n",
    "print(f\"  FP32: {time_fp32:.1f}s\")\n",
    "print(f\"  AMP:  {time_amp:.1f}s\")\n",
    "print(f\"  Speedup: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac457fcb",
   "metadata": {},
   "source": [
    "## 5. Combining Strategies\n",
    "\n",
    "Use multiple strategies together for best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95066e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "models = [\n",
    "    resnet20(10),\n",
    "    wrn_16_2(10),\n",
    "    mobilenet_v2(10)\n",
    "]\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = DMLTrainer(models, learning_rate=0.1, temperature=4.0)\n",
    "\n",
    "# Apply curriculum learning\n",
    "curriculum = CurriculumLearning(num_stages=3)\n",
    "curriculum.apply(trainer)\n",
    "\n",
    "# Apply peer selection\n",
    "peer_selector = PeerSelection(selection_strategy='performance', top_k=2)\n",
    "peer_selector.apply(trainer)\n",
    "\n",
    "# Apply temperature scaling\n",
    "temp_scheduler = TemperatureScaling(\n",
    "    initial_temperature=4.0,\n",
    "    final_temperature=2.0,\n",
    "    schedule='cosine'\n",
    ")\n",
    "temp_scheduler.apply(trainer)\n",
    "\n",
    "# Apply AMP\n",
    "trainer = apply_amp_to_trainer(trainer, AMPConfig(enabled=True))\n",
    "\n",
    "# Train with all strategies\n",
    "print(\"Training with combined strategies...\")\n",
    "results = trainer.train(train_loader, test_loader, epochs=50)\n",
    "\n",
    "print(f\"\\n✓ Final accuracy: {results['avg_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573cd52",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Search\n",
    "\n",
    "Automatically find the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf46600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml-py.utils import HyperparameterSpace, RandomSearcher\n",
    "\n",
    "# Define search space\n",
    "space = HyperparameterSpace({\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'temperature': [2, 3, 4, 5],\n",
    "    'kl_weight': [0.5, 1.0, 2.0]\n",
    "})\n",
    "\n",
    "# Define objective function\n",
    "def objective(config):\n",
    "    models = [resnet20(10), wrn_16_2(10)]\n",
    "    trainer = DMLTrainer(models, **config)\n",
    "    results = trainer.train(train_loader, test_loader, epochs=10)\n",
    "    return results['avg_acc'][-1]\n",
    "\n",
    "# Run search\n",
    "searcher = RandomSearcher(objective, 'accuracy', 'maximize')\n",
    "best_config = searcher.search(space, n_trials=10)\n",
    "\n",
    "print(f\"\\nBest configuration: {best_config}\")\n",
    "searcher.save_results('search_results.json')\n",
    "searcher.plot_results('search_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cb439",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "\n",
    "✅ **Curriculum Learning** - Gradual difficulty increase  \n",
    "✅ **Peer Selection** - Adaptive peer choosing  \n",
    "✅ **Temperature Scaling** - Dynamic temperature adjustment  \n",
    "✅ **Mixed Precision** - Faster training with AMP  \n",
    "✅ **Combined Strategies** - Using multiple techniques together  \n",
    "✅ **Hyperparameter Search** - Automatic optimization  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try these strategies on your own datasets\n",
    "- Experiment with different strategy combinations\n",
    "- Check out `03_distillation_methods.ipynb` for knowledge distillation\n",
    "- See `05_deployment.ipynb` for production deployment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
